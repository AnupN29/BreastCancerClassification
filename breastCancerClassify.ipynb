{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "\n",
    "import os,random, shutil\n",
    "from imutils import paths\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SeparableConv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Train, Validation and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring paths\n",
    "INPUT_DATASET = \"Dataset/archive\"\n",
    "BASE_PATH = \"Dataset/new\"\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalPaths=list(paths.list_images(INPUT_DATASET))\n",
    "random.seed(7)\n",
    "random.shuffle(originalPaths)\n",
    "index=int(len(originalPaths)*TRAIN_SPLIT)\n",
    "trainPaths=originalPaths[:index]\n",
    "testPaths=originalPaths[index:]\n",
    "index=int(len(trainPaths)*VAL_SPLIT)\n",
    "valPaths=trainPaths[:index]\n",
    "trainPaths=trainPaths[index:]\n",
    "datasets=[(\"training\", trainPaths, TRAIN_PATH),\n",
    "          (\"validation\", valPaths, VAL_PATH),\n",
    "          (\"testing\", testPaths, TEST_PATH)\n",
    "]\n",
    "for (setType, originalPaths, basePath) in datasets:\n",
    "        print(f'Building {setType} set')\n",
    "        if not os.path.exists(basePath):\n",
    "                print(f'Building directory {basePath}')\n",
    "                os.makedirs(basePath)\n",
    "        for path in originalPaths:\n",
    "                file=path.split(os.path.sep)[-1]\n",
    "                label=file[-5:-4]\n",
    "                labelPath=os.path.sep.join([basePath,label])\n",
    "                if not os.path.exists(labelPath):\n",
    "                        print(f'Building directory {labelPath}')\n",
    "                        os.makedirs(labelPath)\n",
    "                newPath=os.path.sep.join([labelPath, file])\n",
    "                shutil.copy2(path, newPath)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Cancer Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "shape=(48,48,3)\n",
    "channelDim=-1\n",
    "\n",
    "\n",
    "\n",
    "model.add(SeparableConv2D(32, (3,3), padding=\"same\",input_shape=shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channelDim))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(SeparableConv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channelDim))\n",
    "model.add(SeparableConv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channelDim))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channelDim))\n",
    "model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channelDim))\n",
    "model.add(SeparableConv2D(128, (3,3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=channelDim))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255684 images belonging to 2 classes.\n",
      "Found 42588 images belonging to 2 classes.\n",
      "Found 99938 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setting-up and Image Preprocessing\n",
    "NUM_EPOCHS=5; INIT_LR=1e-2; BS=32\n",
    "\n",
    "trainPaths=list(paths.list_images(TRAIN_PATH))\n",
    "lenTrain=len(trainPaths)\n",
    "lenVal=len(list(paths.list_images(VAL_PATH)))\n",
    "lenTest=len(list(paths.list_images(TEST_PATH)))\n",
    "\n",
    "trainLabels=[int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
    "trainLabels=np_utils.to_categorical(trainLabels)\n",
    "classTotals=trainLabels.sum(axis=0)\n",
    "classWeight=classTotals.max()/classTotals\n",
    "classWeight ={0:classWeight[0],1:classWeight[1]}\n",
    "\n",
    "trainAug = ImageDataGenerator(\n",
    "\trescale=1/255.0,\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.05,\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\tshear_range=0.05,\n",
    "\thorizontal_flip=True,\n",
    "\tvertical_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "\n",
    "valAug=ImageDataGenerator(rescale=1 / 255.0)\n",
    "\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "\tTRAIN_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=True,\n",
    "\tbatch_size=BS)\n",
    "valGen = valAug.flow_from_directory(\n",
    "\tVAL_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "testGen = valAug.flow_from_directory(\n",
    "\tTEST_PATH,\n",
    "\tclass_mode=\"categorical\",\n",
    "\ttarget_size=(48,48),\n",
    "\tcolor_mode=\"rgb\",\n",
    "\tshuffle=False,\n",
    "\tbatch_size=BS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation of model\n",
    "opt=Adagrad(lr=INIT_LR,decay=INIT_LR/NUM_EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52960/1439354680.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  trainedModel=model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7990/7990 [==============================] - 1450s 181ms/step - loss: 0.6300 - accuracy: 0.8153 - val_loss: 0.6305 - val_accuracy: 0.7449\n",
      "Epoch 2/5\n",
      "7990/7990 [==============================] - 1302s 163ms/step - loss: 0.6056 - accuracy: 0.8215 - val_loss: 0.6112 - val_accuracy: 0.7474\n",
      "Epoch 3/5\n",
      "7990/7990 [==============================] - 1329s 166ms/step - loss: 0.6014 - accuracy: 0.8218 - val_loss: 0.6136 - val_accuracy: 0.7479\n",
      "Epoch 4/5\n",
      "7990/7990 [==============================] - 1336s 167ms/step - loss: 0.5982 - accuracy: 0.8225 - val_loss: 0.6193 - val_accuracy: 0.7451\n",
      "Epoch 5/5\n",
      "7990/7990 [==============================] - 1315s 165ms/step - loss: 0.5982 - accuracy: 0.8229 - val_loss: 0.6362 - val_accuracy: 0.7366\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "trainedModel=model.fit_generator(\n",
    "\ttrainGen,\n",
    "\tsteps_per_epoch=lenTrain//BS,\n",
    "\tvalidation_data=valGen,\n",
    "\tvalidation_steps=lenVal//BS,\n",
    "\tclass_weight=classWeight,\n",
    "\tepochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52960/3131523291.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred_indices=model.predict_generator(testGen,steps=(lenTest//BS)+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.66      0.78     71544\n",
      "           1       0.52      0.93      0.67     28394\n",
      "\n",
      "    accuracy                           0.74     99938\n",
      "   macro avg       0.74      0.80      0.73     99938\n",
      "weighted avg       0.84      0.74      0.75     99938\n",
      "\n",
      "[[47083 24461]\n",
      " [ 1849 26545]]\n",
      "Accuracy: 0.736736776801617\n",
      "Specificity: 0.9348806085792774\n",
      "Sensitivity: 0.6580985128033099\n"
     ]
    }
   ],
   "source": [
    "print(\"Now evaluating the model\")\n",
    "testGen.reset()\n",
    "pred_indices=model.predict_generator(testGen,steps=(lenTest//BS)+1)\n",
    "\n",
    "pred_indices=np.argmax(pred_indices,axis=1)\n",
    "\n",
    "print(classification_report(testGen.classes, pred_indices, target_names=testGen.class_indices.keys()))\n",
    "\n",
    "cm=confusion_matrix(testGen.classes,pred_indices)\n",
    "total=sum(sum(cm))\n",
    "accuracy=(cm[0,0]+cm[1,1])/total\n",
    "specificity=cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print(cm)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0,N), trainedModel.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0,N), trainedModel.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0,N), trainedModel.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0,N), trainedModel.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on the Dataset\")\n",
    "plt.xlabel(\"Epoch No.\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show('LossAccPlot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
